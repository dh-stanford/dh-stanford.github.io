<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Why are such terrible things written about DH? Kirsch v. Kirschenbaum :: Digital Humanities @ Stanford</title>

  
  <style>
    body{font-family:sans-serif}a{color:#820000}body>header{background-color:#820000;color:#fff;padding:1rem;text-align:center;font-size:3em}header a{color:#fff;text-decoration:none}.pagination ol{list-style:none;margin:0;padding:0;display:flex;gap:1em}.pagination ol li{outline:1px solid #820000;padding:.25em .5em}main img{display:block;max-width:80%}section.comments{border-top:1px solid #820000;margin-top:2em;padding-top:2em}section.comments header{font-size:1.4em;font-weight:700}
  </style>
</head>

<body>
  <header><a href="/">Digital Humanities @ Stanford</a></header>
  <main role="main">
    
<article class="article">
  <h1>Why are such terrible things written about DH? Kirsch v. Kirschenbaum</h1>
  <small>
    Submitted By: <span>Glen Worthey</span> on <time>Wed May 07 2014 12:01:08 GMT-0700 (Pacific Daylight Time)</time>
  </small>

  

  <p>Last week I read one of the latest and loudest salvos in a sad and very silly war on the digital humanities: Adam Kirsch, in <em>The New Republic</em>, chose to put his pugnacious piece out under not one, but two inflammatory titles: &quot;<a href="http://www.newrepublic.com/article/117428/limits-digital-humanities-adam-kirsch">Technology is Taking Over English Departments: The false promise of the digital humanities</a>.&quot;  Oh, please.</p>
<p>It's an important enough piece of writing, published as it is in such a visible venue, and written well enough (lapses in logic notwithstanding); and what hardscrabble up-start academic field wouldn't be proud to have 4,500 words dedicated to it in a periodical of such prestige?</p>
<blockquote>
<p>Hey, you haven't really arrived till you get attacked in TNR.</p>
<p>— Ted Underwood (@Ted_Underwood) <a href="https://twitter.com/Ted_Underwood/statuses/462265188855468032">May 2, 2014</a></p>
</blockquote>
<p>But what's sad is that the author is so willfully ignorant of what he criticizes and so sweeping in his conclusions; that he cherry-picks his quotes for their potential (if unjustifiable) to outrage, then so readily misreads them.  It's sad that there's so much better digital humanities writing out there, in much less flashy yet still very easy-to-find places.</p>
<p>Thus before going further, I'd like to mention another article published nearly simultaneously with this one: Matt Kirschenbaum's final installment in an &quot;unplanned trilogy,&quot; &quot;<a href="http://mkirschenbaum.wordpress.com/2014/04/24/new-essay-what-is-digital-humanities-and-why-are-they-saying-such-terrible-things-about-it/">What is 'Digital Humanities,' and Why Are They Saying Such Terrible Things about It?</a>&quot;  Kirschenbaum's piece* is written with substantially less fluff than Kirsch's, and it both requires more attention and rewards that attention more richly than the <em>New Republic</em> piece.  But it's a perfect counterpart, for the &quot;terrible things&quot; of Kirschenbaum's title are precisely the things that Kirsch proffers for us to believe.  Kirschenbaum hilariously quotes some of these things in order to justly mock them:</p>
<blockquote>
<p>Digital humanities is a nest of big data ideologues. Digital humanities digs MOOCs. Digital humanities is an artifact of the post-9/11 security and surveillance state (the NSA of the MLA). Like Johnny, digital humanities can’t read. Digital humanities doesn’t do theory. Digital humanities never historicizes. Digital humanities is complicit. Digital humanities is naive. Digital humanities is hollow huckster boosterism. Digital humanities is managerial. Digital humanities is the academic import of Silicon Valley solutionism (the term that is the shibboleth of bad-boy tech critic Evgeny Morozov). Digital humanities cannot abide critique. [...]. Digital humanities does not inhale (easily the best line of the bunch). Digital humanities wears Google Glass. Digital humanities wears thick, thick glasses (guilty). Perhaps most damning of all: digital humanities is something separate from the rest of the humanities, and — this is the real secret — digital humanities wants it that way. (pp. 5-6)</p>
</blockquote>
<p>I quote at some length here because it pains me to spend more time with the worse piece — but unfortunately, it's the worse one that requires more corrective commentary.  The beauty of reading both is that you'll find in Kirsch clear examples of practically all the silly &quot;terrible things&quot; that Kirschenbaum lists for us!  But if you have time to read only one DH article this month, make it the full-throated Kirschenbaum, and not the trivial Kirsch.</p>
<p>But now, sadly, back to the lesser piece.</p>
<p>At the beginning of his essay, Kirsch does the usual dance of claiming that &quot;the question of what the digital humanities is has yet to be given a satisfactory answer.&quot;  This is hogwash: there are many satisfactory answers, and many satisfying, thoughtful approaches to the perennial &quot;What is DH?&quot; question.  Likewise his claim that the field's introspection is &quot;a sign of a field suffering an identity crisis&quot;: says who?  It seems equally plausible to see the self-conscious or self-explanatory tendencies in recent DH publication simply as a sign of a field that is still new to many readers, and thus anxious to introduce itself; or of a field that it is still young enough to retain some understandable zeal instead of the smugness of the traditional.  No matter: Kirsch gives the lie to his own argument when, after beginning by dinging DH for its self-conscious &quot;identity crisis,&quot; he ends by smearing it as over-confident (&quot;the militant confidence of the digital&quot;).</p>
<p>His misreadings are deliberate and numerous, and perhaps too obvious to detail completely — but let's look at a few: when the authors of <a href="https://mitpress.mit.edu/books/digitalhumanities-0"><em>Digital_Humanities</em></a> claim our time as &quot;one of those rare moments of opportunity for the humanities,&quot; Kirsch reads the claim as signaling &quot;nothing less than an epoch in human history.&quot;  No, not &quot;an epoch in human history&quot; — rather, only a much more modest &quot;moment&quot; in an academic discipline.  Kirsch claims to sense an &quot;undertone of menace,&quot; into which he chooses to read the threat that &quot;we can either get on board or stand athwart it and get run over.&quot;  Of course, he doesn't have a quote to back up that menace, that threat: it's purely imaginary.</p>
<p>So too is Kirsch's claim that, &quot;Right before our eyes, options are foreclosed and demands enforced; a future is constructed as though it were being discovered.&quot;  Although the DH authors he cites here may tend toward the more utopian, they certainly do not imply any foreclosed options or enforce (or even make) any demands of any kind: they're just describing their scholarly and pedagogical practice.  When he <a href="http://www.samplereality.com/2009/03/12/whats-wrong-with-writing-essays/">quotes Mark Sample (out of context, natch)</a> about how &quot;the 8-page essay and the 25-page research paper will have to make room for the game design, the multi-player narrative, the video mash-up, the online exhibit and other new forms and formats as pedagogical exercises&quot; — Kirsch claims the menace of a &quot;post-verbal future.&quot;  Not a future where a <em>multiplicity</em> of forms of pedagogy and scholarly argument is welcome, but one where his one particular preferred form (and mine too, I confess) is simply &quot;foreclosed.&quot;  This is pure paranoia.  No digital humanist I've ever known (and I've been in the field for 20 years, and have known legions) has ever been &quot;post-verbal&quot; in any sense of the word.</p>
<p>Kirsch is decidedly old-fashioned, but not in the ways one might imagine.  He complains vigorously about DH's proudly proclaimed collaborative ethos, which traces its philosophical roots in the myth of the solitary genius and the long-accepted idea that knowledge production has always been a collaborative, distributed, social affair.  Then this zinger: &quot;as an empirical matter, the solitary scholar laboring on a singular paradigm-shifting work is quite real.&quot;  No, Mr. Kirsch, it's not.  Even Kirsch's examples of great monographs supposedly written by &quot;solitary scholars,&quot; and the idea that &quot;you can go the library and check them out (or, if that takes too long, download them),&quot; is both superficial and ridiculous: not only were those books inspired and reviewed and edited and published and collected and cataloged and preserved and made available to that &quot;solitary genius&quot; by real people; not only did real people write, collect, curate, preserve, arrange, describe, and make available all the previous scholarship and all the primary sources those monographs were based on, long before our &quot;solitary genius&quot; set his mind to thinking; but even the magical thinking behind Kirsch's snarky &quot;if that takes too long, download them&quot; idea depends, so obviously, on so many people.  The digital humanities' decision (perhaps born of necessity, but still a conscious choice) to pull aside the curtain of scholarship just a little, and to reveal the true collaborative nature of our form of scholarship, only serves to make the pre-digital scholarship a little more honest.  There is no &quot;contradiction between individual genius and digital practice,&quot; but there is a relationship — just as there has never been a contradiction between individual genius and any scholarly practice.</p>
<p>There are of course some interesting questions raised in this article, but rather than supposed nails in DH's supposed coffin, they're very much the same questions that we talk about all the time in the academic DH community.  Kirsch puts one of them this way: &quot;Does the digital component of digital humanities give us new ways to think, or only ways to illustrate what we already know?&quot;  That is not a bad question, but contrary to what Kirsch and his fellow DHaters want us to believe, it can be extremely useful to have a digital approach confirm what we already know (or what we think we already know).  At the very least, DH can enable a new <em>way</em> of knowing it.  New ways of knowing are nothing to sneeze at, even if &quot;the facts&quot; remain more or less the same.  (Of course, we'd also like to think — and we have good evidence for thinking — that digital approaches can also produce new facts, and new knowledge.)</p>
<p>What irks me perhaps most about writers like Kirsch (and he's far from the first, or the most interesting) is that they think they've called our bluff: they believe they've revealed the nakedness of some imaginary DH emperor, just because they don't get it, or because they think they already knew everything there is to know about a topic, or because that some particular thing that an algorithm is newly able to demonstrate in a different way is already familiar to them.  (A notorious <em>New York Times</em> column a few years ago called this the &quot;Duh!&quot; factor in DH.  She claimed to get nothing at all from DH research except for either &quot;Huh?&quot; — for conclusions that she just didn't understand — or &quot;Duh!&quot; — for conclusions that were already obvious before the digital approach.  It's a cute way to put it, but hardly a thoughtful set of reactions to scholarship: more like something I heard in junior high.)  If these journalists, or anyone not engaged in the scholarship of any field, were to focus their attention on <em>any</em> contemporary humanities scholarship, they could easily have the same two trivial reactions.</p>
<p>DH scholarship is not for everyone, just as the vast majority of all scholarly output is not for everyone.  If you don't get it, or you're not interested in it, don't bother with it.  We'll get along fine without you!  We're certainly not immune to intelligent criticism — in fact, we engage in quite a lot of that ourselves — but the trivialization of an entire field of scholarly endeavor, the all-knowing assumptions about what &quot;the computer can tell you&quot; and what it can't, the glaringly obvious idea that &quot;it takes a scholar with a broad knowledge of literary history&quot; to draw conclusions from data, the ridiculous straw man that &quot;computers cannot think better than human beings&quot; — all of these we can do without.  They have nothing to do with the digital humanities, and are poor journalism, too.</p>
<p>Kirsch claims that &quot;humanistic thinking does not proceed by experiments that yield results; it is a matter of mental experiences, provoked by works of art and history, that expand the range of one's understanding and sympathy.&quot;  Evidently the range of Kirsch's own understanding and sympathy has not been sufficiently expanded to embrace (or even to consider honestly, and without prejudice) newer possibilities in humanities research and teaching.  That's a shame, but it's his loss, not that of the digital humanities field.  The greater shame is that unsuspecting readers of <em>The New Republic</em> may be led to believe that the digital humanities has been given a fair trial, or even an intelligent introduction or description.  It hasn't, at least not here.</p>
<p>* Matthew Kirschenbaum, “What is ‘Digital Humanities,’ and Why Are They Saying Such Terrible Things about It?” <em>differences</em> 25.1 (2014): 46-63. Copyright © 2014 Duke University Press.  Pre-print version available on <a href="http://mkirschenbaum.wordpress.com/2014/04/24/new-essay-what-is-digital-humanities-and-why-are-they-saying-such-terrible-things-about-it/">Kirschenbaum's website</a>.</p>


  

  <footer>
    <small>
      <a href=""></a>
    </small>
  </footer>
</article>

  </main>
</body>

</html>
