---
layout: templates/article
title: "How to Write an ADHO DH Conference Proposal in 2023"
author: Quinn Dombrowski
date: 2023-11-14
post_images:
  - ../post-images/adho_new_cos.jpg
---

Four years ago I wrote a [guide to writing DH conference submissions](https://digitalhumanities.stanford.edu/guide-writing-dh-conference-submissions/), a blog post that got a fair bit of traction and seems to be passed around every time there's a new CFP.

The problem is, it's not good advice anymore for the international ADHO digital humanities conference. I've been the ACH representative to ADHO since summer 2021, and one of the major initiatives that ADHO has undertaken has been to rework the review criteria for the conference. Previously, a lot was left to the discretion of the individual program committees, meaning that there could be a lot of variability from year to year in terms of the taxonomies used to classify papers, the review criteria, and even whether your bibliography was properly formatted (see Jennifer Guiliano and Laura Estill, "[What gets categorized counts: Controlled vocabularies, digital affordances, and the international digital humanities conference](https://doi.org/10.1093/llc/fqac091)" for a closer look at the taxonomy issues). The changes from year to year were usually small (though enough to potentially make a difference in your overall score), and because the following year could bring a totally new set of changes, I never saw the need to rewrite that blog post.

That's different now. Christof Sch√∂ch, who led the review criteria revision work, wrapped up that project over the summer, drawing upon feedback from relevant committees (like the Conference Coordinating Committee) as well as a survey of DH conference attendees and the community more broadly. Christof is the current president of the Constituent Organization Board, made up of representatives from all the constituent organization, which collectively provides leadership and direction for ADHO -- which is to say, these review criteria were developed not for this year, but as a set of criteria that we can hopefully work with long-term. I'm sure they'll eventually evolve once put into practice, but this is what we're currently working with. 

The goal of the new review criteria was to elicit constructive feedback and not just negative comments, and functionally make reviewers justify their numeric choices through their text comments. 

## The criteria

The evaluation criteria are as follows:

- Does the submission include a sufficient description of the current state of knowledge and best practices in the area(s) relevant to the work, and is that description backed up by useful references? (20%)
- Does the work described in the submission go beyond the current state of knowledge and best practices in the areas(s) relevant to the work? This may concern method, approach, application domain, or findings. (20%)
- Does the submission describe its approach or method with sufficient detail for readers to understand what was done and why it was done, within the limitations of the abstract format? (20%)
- Does the submission support diversity, in the sense that it describes work that increases the range of topics, approaches and perspectives presented at the DH conference, and/or does it give adequate recognition to a broad range of relevant scholarly work, including by members of disadvantaged or under-represented groups? (15%)
- Is the submission well-structured and clearly written in a way that supports readers in understanding the submission? (15%)
- Overall recommendation. Based on the evaluation criteria overall, but also taking into account any additional criteria or issues you may consider important for the evaluation, do you recommend that this submission be accepted for presentation or not? (10%)


For workshops, the second two points are a little different:

- Does the submission describe the contents of the workshop (topics, issues, methods, tools) in sufficient detail for readers to understand what will be taught? (20%)
- Does the submission describe its didactical approach, the materials to be used, and the progression of topics over the course of the workshop with sufficient detail for readers to understand how the workshop will be taught? (20%)

## Structure of a DH submission

Based on these review criteria, here's how I'd approach structuring a DH submission in 2023:

### Disciplinary context & broad description
What are you doing, broadly speaking, and what makes it interesting or different or new? Don't overthink this too much: doing a pretty standard DH project on a new corpus, archive, or subject matter counts as interesting, if you can convey what's special or important about that corpus, archive, or subject matter. Maybe you're bringing in a new audience (the public, children, retirees), or the subject matter is in a language other than English, or you're working texts in a genre that's under-studied, or there's some connection to current events. Maybe it relates to something that's really important in your discipline. For anything disciplinary, lean towards *over-explaining it*. You might get a reviewer from a very different discipline, for whom it isn't at all self-evident what the major debates are in your field. Explain this like you would to an educated but non-academic relative over the holidays. Even things like questions of DH labor that don't necessarily seem disciplinary in nature often depend on different academic cultures that vary across countries, and you can't assume you'll automatically share that context with your reviewer. If you were writing a grant proposal for your thing, why should it be funded? That's similar to your pitch here. This portion is also a good place to address the question of diversity -- and for a lot of projects, the "what makes this new" is basically the same as "how does this contribute to diversity". If you want to draw the reader's attention to this very clearly (which helps them out as they're writing the review), you can be explicit about how some aspects of your project would make it contribute to the diversity of the work presented at the conference. 

### DH context and citations
Make sure you contextualize what you're doing within the field of DH, and have citations. Do a little research in DH journals and the [Index of DH Conferences](https://dh-abstracts.library.virginia.edu/). It's fine to also talk about what you're doing in the context of your disciplinary field, but I'd guess that there will be some expectation that you have some idea what's going on in DH that's relevant to your proposal -- after all, it's a DH conference. Also, don't just cite the usual go-to figures in the history of DH. Citing a more diverse group of scholars -- ideally, not just from the US and UK -- also contributes to the diversity parameter.

### Detailed description

What are you doing -- concretely, and specifically? With DH conferences, you can and should assume that people are much more technical, or at least technically-inclined, than the reviewers at your disciplinary conferences. Don't go overboard with detail: you don't need to list every library you're using in your code, but please do talk about technical specifics! If there are multiple algorithms you could be using for your task, you can say which one you've picked and why. You can mention which NLP library you're using, or any interesting or significant choices in processing your data. One of the things about DH being an interdisciplinary field and conference is that the technical section is likely to be more immediately accessible to your reviewer than the disciplinary piece of your proposal. In short, you don't have to define what NLP is, but the trade-off is that your reviewer will want you to say specifically what you're doing and "text analysis" won't cut it. 

Note that at least for DH 2024, there's an option for requesting a "technical" reviewer, whereby the [DHTech SIG](https://dh-tech.github.io/) will try to find you a reviewer with specific technical expertise to review your proposal. So if you really want to go all in on technical detail, you can do that this year for the first time without it being a total dice roll whether the reviewer will be able to follow you down that rabbit hole.

### Stakes

I like wrapping up abstracts with a clear reiteration of the stakes. Again, why is this important? What new perspective or knowledge does it offer? How is this going to be relevant for scholars who don't work on exactly what you do (or may only share a few methods in common with you, while working in a very different field, institutional context, and national context).

## What if the project isn't done?

It's rough having to submit something in December for a conference next August. The safest route is to write up a project that you're already done with, where you can clearly state what you did and the outcomes. Personally, though, I hate doing that: if I'm done with a thing, I'm probably bored with it, and writing a proposal about something I'm done with is boredom that promises future boredom when I have to prep slides late next summer.

The wisdom of putting in a proposal for an unfinished project depends on how much your confidence can make up the gap in the work that's done. If you've done a fair bit of work on something and have gotten a sense for the shape it's taking, it's a smaller bluff than if you put in a proposal for something you haven't started yet. (I've done both!)

If you're writing up work that isn't done yet, don't use the future tense. That makes the situation too obvious. I'll often use the present tense (e.g. "In this project, we use topic modeling on a corpus consisting of..."). If you're proposing something completely new, give yourself some leeway by not picking one single method, because then it'll be very awkward if it turns out that doesn't work for some reason. You can talk about "using a range of techniques, including..." and list a set of viable things that you've used before and can talk about competently in the detailed technical description section. If everything else is in order with your proposal, you can probably get away with some hand-waving when it comes to the details of your actual findings if you can say something vague. It's probably a fair bet that they'll be complex and will reveal something -- you can riff on that.

DH 2024, at least, will have a meaningful hybrid component, so even if Washington, DC in August isn't your idea of a fun trip, you can still share what you're working on with the international DH community! It's a joy to see presentations from students and folks who are new to DH but are doing interesting things. Don't be intimidated, put in an abstract! 

(I shouldn't have to say this, but I will anyway: please, please do not try to get ChatGPT to write this for you, even prompting from the outline. There's a lot of DH folks who've been playing with LLMs and the odds of getting someone who's very familiar with the kind of language they use are not small. Plus, it sucks at the kind of specific, concrete detail you'll need for a successful proposal. If you're not a native speaker of English, by all means have ChatGPT do a copyediting pass but write the thing yourself.)

And if this conference still feels like a bit much, there'll be a virtual ACH conference in fall 2024 with in-person "hubs". The vibes of those review criteria are different, and I'll probably write another explainer in the spring when the ACH CFP is posted.